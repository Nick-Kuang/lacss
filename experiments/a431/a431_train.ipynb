{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1126634-09c9-43db-957c-452f7c78fdcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from functools import partial\n",
    "from logging.config import valid_ident\n",
    "from os.path import join\n",
    "\n",
    "from tqdm import tqdm\n",
    "import flax.linen as nn\n",
    "from flax.core.frozen_dict import freeze,unfreeze\n",
    "from flax.training.train_state import TrainState\n",
    "from jax.config import config\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "import lacss\n",
    "from lacss.utils import show_images\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "#########################################\n",
    "\n",
    "datapath: str = \"../../../a431\"\n",
    "transfer: str = '../../runs/supervised/20230307-164258/convnext_p4.pkl'\n",
    "logpath: str = \"../../runs/a431_train/\"\n",
    "seed: int = 42\n",
    "batchsize: int = 1\n",
    "n_epochs: int = 15\n",
    "warmup_epochs: int = 3\n",
    "steps_per_epoch: int = 3000\n",
    "init_epoch: int = 0\n",
    "size_loss: float = 0.01\n",
    "n_buckets: int = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bfeca7-0e5b-4131-9973-bd1130c78aab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../runs/a431_train/20230324-1150'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "log_sub_dir = time.strftime(\"%Y%m%d-%H%M\")\n",
    "logpath = join(logpath, log_sub_dir)\n",
    "logpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633b9d93-8631-497b-8ab6-6e83ffa94679",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/FCAM/jyu/.cache/pypoetry/virtualenvs/lacss-jy6iEdVP-py3.8/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "def train_parser_semisupervised(inputs):\n",
    "    inputs = lacss.data.parse_train_data_func(\n",
    "        inputs, size_jitter=(0.85, 1.15)\n",
    "    )\n",
    "\n",
    "    image = inputs[\"image\"]\n",
    "    image = tf.image.random_contrast(image, 0.6, 1.4)\n",
    "    image = tf.image.random_brightness(image, 0.3)\n",
    "\n",
    "    gt_locations = inputs[\"locations\"]\n",
    "\n",
    "    x_data = dict(image=image, gt_locations=gt_locations)\n",
    "\n",
    "    return x_data\n",
    "\n",
    "\n",
    "def val_parser(inputs):\n",
    "    return (\n",
    "        dict(\n",
    "            image=inputs[\"image\"],\n",
    "        ),\n",
    "        dict(\n",
    "            gt_boxes=inputs[\"bboxes\"],\n",
    "            gt_locations=inputs[\"locations\"],\n",
    "            gt_labels=inputs['label'],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "ds_train = lacss.data.dataset_from_simple_annotations(\n",
    "    join(datapath, \"train.json\"),\n",
    "    join(datapath, 'train'),\n",
    "    [512,512,1],\n",
    ")\n",
    "\n",
    "ds_train = ds_train.repeat().map(train_parser_semisupervised)\n",
    "ds_train = ds_train.filter(lambda x: tf.size(x['gt_locations']) > 0)\n",
    "ds_train = ds_train.bucket_by_sequence_length(\n",
    "    element_length_func=lambda x: tf.shape(x[\"gt_locations\"])[0],\n",
    "    bucket_boundaries=list(np.arange(1, n_buckets) * (2056 // n_buckets) + 1),\n",
    "    bucket_batch_sizes=(batchsize,) * n_buckets,\n",
    "    padding_values=-1.0,\n",
    "    pad_to_bucket_boundary=True,\n",
    ")\n",
    "\n",
    "imglist = glob.glob(join(datapath, 'test', 'img*'))\n",
    "masklist = glob.glob(join(datapath, 'test', 'mask*'))\n",
    "imglist.sort()\n",
    "masklist.sort()\n",
    "ds_val = lacss.data.dataset_from_img_mask_pairs(imglist, masklist, [512,512,1])\n",
    "ds_val = ds_val.map(val_parser).batch(1)\n",
    "\n",
    "train_data = lacss.train.TFDatasetAdapter(ds_train, steps=-1).get_dataset()\n",
    "val_data = lacss.train.TFDatasetAdapter(ds_val).get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cae311-8c62-40bf-8b46-6878d91cc1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(transfer, 'rb') as f:\n",
    "    module, params = pickle.load(f)\n",
    "\n",
    "cfg = dict(cfg=dataclasses.asdict(module), aux_edge_cfg={}, aux_fg_cfg={})\n",
    "model = lacss.modules.lacss.LacssWithHelper(**cfg)\n",
    "losses = [\n",
    "    lacss.losses.LPNLoss(),\n",
    "    lacss.losses.AuxEdgeLoss(),\n",
    "    lacss.losses.InstanceOverlapLoss(),\n",
    "    lacss.losses.AuxSizeLoss(size_loss),\n",
    "    lacss.losses.AuxSegLoss(),\n",
    "]\n",
    "\n",
    "trainer = lacss.train.Trainer(\n",
    "    model=model,\n",
    "    optimizer = optax.adamw(0.001),\n",
    "    losses=losses,\n",
    "    seed=seed,\n",
    "    strategy=lacss.train.strategy.VMapped,\n",
    ")\n",
    "\n",
    "trainer.initialize(val_data)\n",
    "\n",
    "new_params = unfreeze(trainer.params)\n",
    "new_params.update(dict(_lacss=params))\n",
    "trainer.state = trainer.state.replace(params = freeze(new_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0d5114-8904-414b-96b8-96e9fc81ebd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2999it [12:45,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 1\n",
      "lpnloss:0.1484, aux_edge_loss:0.0125, instance_overlap_loss:0.0593, aux_size_loss:0.5071, aux_seg_loss:0.3634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [18:11, 68.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_ap: [0.79969079 0.25104126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5999it [26:39,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 2\n",
      "lpnloss:0.1351, aux_edge_loss:0.0119, instance_overlap_loss:0.0528, aux_size_loss:0.4989, aux_seg_loss:0.3890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [29:05, 43.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_ap: [0.75184496 0.22982508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8999it [37:40,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 3\n",
      "lpnloss:0.1316, aux_edge_loss:0.0118, instance_overlap_loss:0.0511, aux_size_loss:0.4963, aux_seg_loss:0.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9000it [40:06,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_ap: [0.72635047 0.2301628 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = init_epoch\n",
    "pb = tqdm(trainer.train(train_data, rng_cols=[\"droppath\"], training=True))\n",
    "for steps, logs in enumerate(pb):\n",
    "    if epoch >= warmup_epochs:\n",
    "        break\n",
    "\n",
    "    if (steps + 1) % steps_per_epoch == 0:\n",
    "        epoch += 1\n",
    "        print(f\"epoch - {epoch}\")\n",
    "        print(\", \".join([f\"{k}:{v:.4f}\" for k, v in logs.items()]))\n",
    "\n",
    "        trainer.checkpoint(join(logpath, f\"cp-{epoch}\"))\n",
    "        trainer.reset()\n",
    "\n",
    "        val_metrics = [\n",
    "            lacss.metrics.BoxAP([0.5, 0.75]),\n",
    "        ]\n",
    "        var_logs = trainer.test_and_compute(val_data, val_metrics)\n",
    "        for k,v in var_logs.items():\n",
    "            print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e99390-ed0f-4242-a72f-8720e17e01bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2999it [12:56,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 4\n",
      "lpnloss:0.1293, aux_edge_loss:0.0115, aux_seg_loss:0.2927, self_supervised_instance_loss:0.8574, aux_size_loss:0.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [15:22, 30.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_ap: [7.28442077e-01 6.52729593e-01 5.53512480e-01 4.47436631e-01\n",
      " 3.18688217e-01 1.70477299e-01 5.07402970e-02 4.85481824e-03\n",
      " 1.98393802e-05 3.08018523e-08]\n",
      "box_ap: [0.70729711 0.18329339]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5999it [23:50,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 5\n",
      "lpnloss:0.1274, aux_edge_loss:0.0113, aux_seg_loss:0.2935, self_supervised_instance_loss:0.8569, aux_size_loss:0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [26:16, 30.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_ap: [7.27726944e-01 6.50544451e-01 5.60518476e-01 4.53828486e-01\n",
      " 3.29050231e-01 1.83473393e-01 5.73567111e-02 4.58546716e-03\n",
      " 1.57186339e-05 2.94978986e-08]\n",
      "box_ap: [0.69781834 0.18571672]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8999it [34:45,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 6\n",
      "lpnloss:0.1263, aux_edge_loss:0.0114, aux_seg_loss:0.2997, self_supervised_instance_loss:0.8572, aux_size_loss:0.4726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [36:11, 18.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_ap: [7.05326943e-01 6.32402377e-01 5.45732444e-01 4.32433293e-01\n",
      " 3.08288495e-01 1.64401068e-01 4.73850784e-02 4.61077866e-03\n",
      " 2.00809774e-05 3.09858457e-08]\n",
      "box_ap: [0.68668721 0.16825018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11999it [44:39,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 7\n",
      "lpnloss:0.1251, aux_edge_loss:0.0116, aux_seg_loss:0.2988, self_supervised_instance_loss:0.8568, aux_size_loss:0.4714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12001it [47:05, 30.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_ap: [6.65602905e-01 5.91378026e-01 5.15534028e-01 4.14065342e-01\n",
      " 2.93778311e-01 1.60895714e-01 5.04911295e-02 4.51283167e-03\n",
      " 1.38459266e-05 2.96980539e-08]\n",
      "box_ap: [0.63343889 0.15873369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13624it [52:37,  4.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     10\u001b[0m pb \u001b[38;5;241m=\u001b[39m tqdm(trainer\u001b[38;5;241m.\u001b[39mtrain(train_data, rng_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdroppath\u001b[39m\u001b[38;5;124m\"\u001b[39m], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m steps, logs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pb):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_epochs:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lacss-jy6iEdVP-py3.8/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/proj_lacss/lacss/lacss/train/trainer.py:106\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, dataset, strategy, rng_cols, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m train_fn \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mtrain_step\n\u001b[1;32m    103\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[1;32m    104\u001b[0m     apply_fn\u001b[38;5;241m=\u001b[39m_cached_partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mapply_fn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m )\n\u001b[0;32m--> 106\u001b[0m state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_logs, preds \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_logs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrngs\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(apply_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mapply_fn)\n\u001b[1;32m    111\u001b[0m batch_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_log()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lacss-jy6iEdVP-py3.8/lib/python3.8/site-packages/flax/core/frozen_dict.py:162\u001b[0m, in \u001b[0;36mFrozenDict.tree_unflatten\u001b[0;34m(cls, keys, values)\u001b[0m\n\u001b[1;32m    159\u001b[0m   sorted_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict)\n\u001b[1;32m    160\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m sorted_keys]), \u001b[38;5;28mtuple\u001b[39m(sorted_keys)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, keys, values):\n\u001b[1;32m    164\u001b[0m   \u001b[38;5;66;03m# data is already deep copied due to tree map mechanism\u001b[39;00m\n\u001b[1;32m    165\u001b[0m   \u001b[38;5;66;03m# we can skip the deep copy in the constructor\u001b[39;00m\n\u001b[1;32m    166\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, values)}, __unsafe_skip_copy__\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.losses = [\n",
    "    lacss.losses.LPNLoss(),\n",
    "    lacss.losses.AuxEdgeLoss(),\n",
    "    lacss.losses.AuxSegLoss(),\n",
    "    lacss.losses.SelfSupervisedInstanceLoss(ver=2),\n",
    "    lacss.losses.AuxSizeLoss(size_loss),\n",
    "]\n",
    "trainer.reset()\n",
    "\n",
    "pb = tqdm(trainer.train(train_data, rng_cols=[\"droppath\"], training=True))\n",
    "for steps, logs in enumerate(pb):\n",
    "    if epoch >= n_epochs:\n",
    "        break\n",
    "\n",
    "    if (steps + 1) % steps_per_epoch == 0:\n",
    "        epoch += 1\n",
    "        print(f\"epoch - {epoch}\")\n",
    "        print(\", \".join([f\"{k}:{v:.4f}\" for k, v in logs.items()]))\n",
    "\n",
    "        trainer.checkpoint(join(logpath, f\"cp-{epoch}\"))\n",
    "        trainer.reset()\n",
    "\n",
    "        val_metrics = [\n",
    "            lacss.metrics.MaskAP([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]),\n",
    "            # lacss.metrics.LoiAP([0.2, 0.5, 1.0]),\n",
    "            lacss.metrics.BoxAP([0.5, 0.75]),\n",
    "        ]\n",
    "        var_logs = trainer.test_and_compute(val_data, val_metrics)\n",
    "        for k,v in var_logs.items():\n",
    "            print(f\"{k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
