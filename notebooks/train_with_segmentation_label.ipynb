{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kks5J-TD8-Bh"
      },
      "source": [
        "# LACSS Supervised Training Demo\n",
        "\n",
        "This notebook shows the general workflow of supervised training an LACSS model from scratch. \n",
        "\n",
        "This data uses a small dataset from the [Cell Image Library](http://www.cellimagelibrary.org/home) collection.\n",
        "\n",
        "We will go through these steps:\n",
        "\n",
        "- Setup the data pipeline\n",
        "- Initialize a model trainer\n",
        "- Perform model training\n",
        "- Visualize the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp1Y6zHl9ddY"
      },
      "source": [
        "## Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ivh9LzC89QK"
      },
      "outputs": [],
      "source": [
        "!pip install lacss\n",
        "\n",
        "import imageio\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "\n",
        "from skimage.color import label2rgb\n",
        "from tqdm import tqdm\n",
        "from os.path import join\n",
        "\n",
        "import lacss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0QliBABDOh"
      },
      "source": [
        "## Data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqdox1oOccv4"
      },
      "outputs": [],
      "source": [
        "# First download the dataset\n",
        "\n",
        "!wget -c https://data.mendeley.com/public-files/datasets/894mmsd9nj/files/568e524f-9a95-45a6-9f80-3619969c2a37/file_downloaded -O images.zip\n",
        "\n",
        "import zipfile\n",
        "\n",
        "data_path = 'image_data'\n",
        "with zipfile.ZipFile('images.zip', \"r\") as f:\n",
        "    f.extractall(data_path)\n",
        "\n",
        "img = imageio.imread(join(data_path, 'train', '000_img.png'))\n",
        "gt = imageio.imread(join(data_path, 'train', '000_masks.png'))\n",
        "\n",
        "lacss.utils.show_images([\n",
        "    img,\n",
        "    gt,\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGjwDe_GhRNu"
      },
      "source": [
        "Lacss expect training data from a python generator that produces the following data:\n",
        "\n",
        "```\n",
        "x_data, y_data = (\n",
        "  {\n",
        "    \"image\": ndarray[B, W, H, C],\n",
        "    \"gt_locations\": ndarray[B, N, 2]\n",
        "  },\n",
        "  {\n",
        "    \"gt_labels\": ndarray[B, W, H]\n",
        "  }\n",
        ")\n",
        "```\n",
        "\n",
        "Here we will set up the data pipeline using tensorflow.dataset library, which has many useful utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3bSK8QDEKlM"
      },
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "\n",
        "imgfiles = [join(data_path, 'train', f'{k:03d}_img.png') for k in range(89)]\n",
        "maskfiles = [join(data_path, 'train', f'{k:03d}_masks.png') for k in range(89)]\n",
        "\n",
        "# create a tensowflow dataset from the files on disk\n",
        "ds = lacss.data.dataset_from_img_mask_pairs(imgfiles, maskfiles)\n",
        "\n",
        "def parser(data):\n",
        "\n",
        "    image = data['image']\n",
        "    label = data['label']\n",
        "    locations = data['locations']\n",
        "\n",
        "    height = tf.shape(image)[0]\n",
        "    width = tf.shape(image)[1]\n",
        "\n",
        "    # simple augmentations\n",
        "    if tf.random.uniform(()) >= 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        label = label[:, ::-1]\n",
        "        locations = locations * [1, -1] + [0, width-1]\n",
        "\n",
        "    if tf.random.uniform(()) >= 0.5:\n",
        "        image = tf.image.flip_up_down(image)\n",
        "        label = label[::-1, :]\n",
        "        locations = locations * [-1, 1] + [height-1, 0]\n",
        "\n",
        "    # It is important to pad the locations tensor so that all elements of the dataset are of the same shape\n",
        "    n_pad = 256 - len(locations)\n",
        "    locations = tf.pad(locations, [[0, n_pad], [0,0]], constant_values=-1)\n",
        "\n",
        "    return (\n",
        "        dict(\n",
        "            image = image,\n",
        "            gt_locations = locations, \n",
        "        ),\n",
        "        dict(\n",
        "            gt_labels = label,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "ds = ds.map(parser).repeat().batch(batch_size)\n",
        "\n",
        "# make sure the dataset has the correct element structure\n",
        "ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ4ibyHzEUO7"
      },
      "outputs": [],
      "source": [
        "# Convert the td.dataset to generator\n",
        "train_gen = lacss.train.TFDatasetAdapter(ds, steps=-1).get_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GESuO6zM9tso"
      },
      "source": [
        "## Initialize a trainer\n",
        "\n",
        "- LPNLoss() is the loss function to train the detection head\n",
        "- SupervisedInstanceLoss() trains the segmentation head\n",
        "- The VMapped strategy will compute on batched input data on a single GPU. Use other stratagy if your setup is different (eg. TPU training)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2mp9sJM-Tul"
      },
      "outputs": [],
      "source": [
        "# Model Hyperparameters\n",
        "cfg_json = '''\n",
        "{\n",
        "  \"backbone\": \"ConvNeXt\",\n",
        "  \"backbone_cfg\": {\n",
        "  \t\"depths\": [3,3,27,3],\n",
        "  \t\"drop_path_rate\": 0.4\n",
        "  },\n",
        "  \"detector\": {\n",
        "    \"test_max_output\": 256,\n",
        "    \"train_max_output\": 256\n",
        "  },\n",
        "  \"segmentor\": {\n",
        "    \"conv_spec\": [[384,384,384],[64]],\n",
        "    \"feature_level\": 2,\n",
        "    \"instance_crop_size\": 128,\n",
        "    \"learned_encoding\": true\n",
        "  }\n",
        "}\n",
        "'''\n",
        "\n",
        "import json\n",
        "lacss_cfg = json.loads(cfg_json)\n",
        "\n",
        "trainer = lacss.train.Trainer(\n",
        "    model=lacss.modules.Lacss(**lacss_cfg),\n",
        "    losses=[\n",
        "        lacss.losses.LPNLoss(),\n",
        "        lacss.losses.SupervisedInstanceLoss(),\n",
        "    ],\n",
        "    optimizer=optax.adam(0.001),\n",
        "    strategy=lacss.train.strategy.VMapped,\n",
        "    seed=1234, # RNG seed\n",
        ")\n",
        "trainer.initialize(train_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5qcbxs5aomk"
      },
      "source": [
        "## Training\n",
        "\n",
        "Trainer.train() function returns an iterator, stepping through which will drive the training of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09jrmOyjaoAs"
      },
      "outputs": [],
      "source": [
        "n_epoch = 10\n",
        "steps_per_epoch = 3000\n",
        "\n",
        "train_iter = trainer.train(train_gen, rng_cols=[\"droppath\"], training=True)\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  \n",
        "  print(f\"Epoch {epoch+1}\")\n",
        "\n",
        "  for steps in tqdm(range(steps_per_epoch)):\n",
        "\n",
        "      logs = next(train_iter)\n",
        "\n",
        "  print(\", \".join([f\"{k}:{v:.4f}\" for k, v in logs.items()]))\n",
        "\n",
        "  # reset logs\n",
        "  trainer.reset()\n",
        "\n",
        "  # perform validation here\n",
        "\n",
        "  # maybe save a training checkpoint\n",
        "  # trainer.checkpoint(f\"cp-{epoch}\")\n",
        "\n",
        "# save the current model\n",
        "trainer.save_model(\"model.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_tBseBbc-mw"
      },
      "source": [
        "## Visualize  the model prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qOX43ZnYyX-"
      },
      "outputs": [],
      "source": [
        "image = imageio.imread(join(data_path, 'test', '000_img.png'))\n",
        "gt = imageio.imread(join(data_path, 'test', '000_masks.png'))\n",
        "\n",
        "# normalize\n",
        "img = image - image.mean()\n",
        "img /= img.std()\n",
        "\n",
        "# prediction\n",
        "model_output = trainer.model.apply(\n",
        "    dict(params=trainer.params),\n",
        "    image = img,\n",
        ")\n",
        "pred = lacss.ops.patches_to_label(model_output, input_size=img.shape[:2])\n",
        "pred = np.asarray(pred)\n",
        "\n",
        "lacss.utils.show_images([\n",
        "    img,\n",
        "    label2rgb(pred, bg_label=0),\n",
        "    label2rgb(gt, bg_label=0),\n",
        "])\n",
        "titles = ['Input', \"Prediction\", \"Ground Truth\"]\n",
        "[ax.set_title(title) for ax, title in zip(plt.gcf().get_axes(), titles)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLVdHJkJ3cVo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
